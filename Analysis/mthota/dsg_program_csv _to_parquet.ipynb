{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://172.18.96.63:4041\n",
       "SparkContext available as 'sc' (version = 2.3.1, master = local[*], app id = local-1555145613231)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-13 14:23:37 WARN  SparkContext:66 - Using an existing SparkContext; some configuration may not take effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.SparkSession\n",
       "import org.apache.spark.sql.types._\n",
       "spark: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@764c7df8\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.SparkSession\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val spark = SparkSession.builder\n",
    "      .appName(\"dsg_prg\")\n",
    "      .master(\"local[*]\")\n",
    "      .config(\"spark.sql.sources.partitionOverwriteMode\",\"dynamic\")\n",
    "      .enableHiveSupport()\n",
    "      .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(PROGRAM_ID,StringType,true), StructField(SUBCATEGORY_ID,StringType,true), StructField(PROGRAM_SOURCE_ID,StringType,true), StructField(PROGRAM_AIRING_TYPE_ID,StringType,true), StructField(CATEGORY_ID,StringType,true), StructField(CAPTION_ID,StringType,true), StructField(PROGRAM_COLOR_TYPE_ID,StringType,true), StructField(MASTER_TITLE,StringType,true), StructField(RELEASE_YEAR,StringType,true), StructField(EPISODE_TITLE,StringType,true), StructField(EPISODE_NUMBER,StringType,true), StructField(STEREO_ENABLED_YN,StringType,true), StructField(STAR_RATING,StringType,true), StructField(SERIES_YN,StringType,true), StructField(RATING_ID_TV_US,StringType,true), StructField(RATING_ID_MOVIE_US,StringType,true), StructField(SERI..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val schema = StructType(Array(\n",
    "    StructField(\"PROGRAM_ID\", StringType, true), StructField(\"SUBCATEGORY_ID\", StringType, true),\n",
    "    StructField(\"PROGRAM_SOURCE_ID\", StringType, true), StructField(\"PROGRAM_AIRING_TYPE_ID\", StringType, true),\n",
    "    StructField(\"CATEGORY_ID\", StringType, true), StructField(\"CAPTION_ID\", StringType, true),\n",
    "    StructField(\"PROGRAM_COLOR_TYPE_ID\", StringType, true), StructField(\"MASTER_TITLE\", StringType, true),\n",
    "    StructField(\"RELEASE_YEAR\", StringType, true), StructField(\"EPISODE_TITLE\", StringType, true),\n",
    "    StructField(\"EPISODE_NUMBER\", StringType, true), StructField(\"STEREO_ENABLED_YN\", StringType, true),\n",
    "    StructField(\"STAR_RATING\", StringType, true), StructField(\"SERIES_YN\", StringType, true),\n",
    "    StructField(\"RATING_ID_TV_US\", StringType, true), StructField(\"RATING_ID_MOVIE_US\", StringType, true),\n",
    "    StructField(\"SERIES_MASTER_YN\", StringType, true), StructField(\"PARENT_PROGRAM_ID\", StringType, true),\n",
    "    StructField(\"RUNTIME\", StringType, true), StructField(\"HDTV_YN\", StringType, true),\n",
    "    StructField(\"BRACKET_TEXT\", StringType, true), StructField(\"PART_NUMBER\", StringType, true),\n",
    "    StructField(\"PART_TOTAL\", StringType, true), StructField(\"ORIGINAL_ADT\", StringType, true),\n",
    "    StructField(\"SUBTITLE\", StringType, true), StructField(\"EVENT_DATE\", StringType, true),\n",
    "    StructField(\"TAG\", StringType, true), StructField(\"Cosmo_program_id\", StringType, true),\n",
    "    StructField(\"link_region_id\", StringType, true), StructField(\"status_code\", StringType, true)\n",
    "))\n",
    "val dsg_df = spark.read.schema(schema).csv(\"/Users/mthota/Dropbox/Data/Data/Program/correct File/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+-----------------+----------------------+-----------+----------+---------------------+------------+------------+-------------+--------------+-----------------+-----------+---------+---------------+------------------+----------------+-----------------+-------+-------+------------+-----------+----------+------------+--------+----------+----+----------------+--------------+-----------+\n",
      "|PROGRAM_ID|SUBCATEGORY_ID|PROGRAM_SOURCE_ID|PROGRAM_AIRING_TYPE_ID|CATEGORY_ID|CAPTION_ID|PROGRAM_COLOR_TYPE_ID|MASTER_TITLE|RELEASE_YEAR|EPISODE_TITLE|EPISODE_NUMBER|STEREO_ENABLED_YN|STAR_RATING|SERIES_YN|RATING_ID_TV_US|RATING_ID_MOVIE_US|SERIES_MASTER_YN|PARENT_PROGRAM_ID|RUNTIME|HDTV_YN|BRACKET_TEXT|PART_NUMBER|PART_TOTAL|ORIGINAL_ADT|SUBTITLE|EVENT_DATE| TAG|Cosmo_program_id|link_region_id|status_code|\n",
      "+----------+--------------+-----------------+----------------------+-----------+----------+---------------------+------------+------------+-------------+--------------+-----------------+-----------+---------+---------------+------------------+----------------+-----------------+-------+-------+------------+-----------+----------+------------+--------+----------+----+----------------+--------------+-----------+\n",
      "|         3|            52|             5617|                  NULL|          5|      NULL|                    1|     Off-Air|        NULL|         NULL|          NULL|                Y|       NULL|        N|              9|              NULL|               Y|             NULL|   1800|      N|        NULL|       NULL|      NULL|        NULL|    NULL|      NULL|NULL|            NULL|             3|          1|\n",
      "+----------+--------------+-----------------+----------------------+-----------+----------+---------------------+------------+------------+-------------+--------------+-----------------+-----------+---------+---------------+------------------+----------------+-----------------+-------+-------+------------+-----------+----------+------------+--------+----------+----+----------------+--------------+-----------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "res2: Long = 831554\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsg_df.show(1)\n",
    "dsg_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "//dsg_df.repartition(1).write.option(\"header\", true).parquet(\"../Data/Program/Parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PROGRAM_ID: string (nullable = true)\n",
      " |-- SUBCATEGORY_ID: string (nullable = true)\n",
      " |-- PROGRAM_SOURCE_ID: string (nullable = true)\n",
      " |-- PROGRAM_AIRING_TYPE_ID: string (nullable = true)\n",
      " |-- CATEGORY_ID: string (nullable = true)\n",
      " |-- CAPTION_ID: string (nullable = true)\n",
      " |-- PROGRAM_COLOR_TYPE_ID: string (nullable = true)\n",
      " |-- MASTER_TITLE: string (nullable = true)\n",
      " |-- RELEASE_YEAR: string (nullable = true)\n",
      " |-- EPISODE_TITLE: string (nullable = true)\n",
      " |-- EPISODE_NUMBER: string (nullable = true)\n",
      " |-- STEREO_ENABLED_YN: string (nullable = true)\n",
      " |-- STAR_RATING: string (nullable = true)\n",
      " |-- SERIES_YN: string (nullable = true)\n",
      " |-- RATING_ID_TV_US: string (nullable = true)\n",
      " |-- RATING_ID_MOVIE_US: string (nullable = true)\n",
      " |-- SERIES_MASTER_YN: string (nullable = true)\n",
      " |-- PARENT_PROGRAM_ID: string (nullable = true)\n",
      " |-- RUNTIME: string (nullable = true)\n",
      " |-- HDTV_YN: string (nullable = true)\n",
      " |-- BRACKET_TEXT: string (nullable = true)\n",
      " |-- PART_NUMBER: string (nullable = true)\n",
      " |-- PART_TOTAL: string (nullable = true)\n",
      " |-- ORIGINAL_ADT: string (nullable = true)\n",
      " |-- SUBTITLE: string (nullable = true)\n",
      " |-- EVENT_DATE: string (nullable = true)\n",
      " |-- TAG: string (nullable = true)\n",
      " |-- Cosmo_program_id: string (nullable = true)\n",
      " |-- link_region_id: string (nullable = true)\n",
      " |-- status_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dsg_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|SUBCATEGORY_ID|\n",
      "+--------------+\n",
      "|             7|\n",
      "|            51|\n",
      "|            15|\n",
      "|            54|\n",
      "|            11|\n",
      "|            29|\n",
      "|            69|\n",
      "|            42|\n",
      "|            73|\n",
      "|             3|\n",
      "|            30|\n",
      "|            34|\n",
      "|            59|\n",
      "|             8|\n",
      "|            28|\n",
      "|            22|\n",
      "|            52|\n",
      "|            16|\n",
      "|            35|\n",
      "|            71|\n",
      "+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dsg_df.select(\"SUBCATEGORY_ID\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsg_df.repartition(1).write.option(\"header\",\"true\").csv(\"/Users/mthota/Dropbox/Data/Data/Program/correct File/csvwithHeaders/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsg_df.repartition(1).write.option(\"header\",\"true\").parquet(\"/Users/mthota/Dropbox/Data/Data/Program/correct File/parquetwithHeaders/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [PROGRAM_ID: string, SUBCATEGORY_ID: string ... 28 more fields]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = spark.read.parquet(\"/Users/mthota/Dropbox/Data/Data/Program/correct File/parquetwithHeaders/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.DataFrame = [PROGRAM_ID: string, SUBCATEGORY_ID: string ... 28 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = spark.read.option(\"header\",\"true\").csv(\"/Users/mthota/Dropbox/Data/Data/Program/correct File/csvwithHeaders/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PROGRAM_ID: string (nullable = true)\n",
      " |-- SUBCATEGORY_ID: string (nullable = true)\n",
      " |-- PROGRAM_SOURCE_ID: string (nullable = true)\n",
      " |-- PROGRAM_AIRING_TYPE_ID: string (nullable = true)\n",
      " |-- CATEGORY_ID: string (nullable = true)\n",
      " |-- CAPTION_ID: string (nullable = true)\n",
      " |-- PROGRAM_COLOR_TYPE_ID: string (nullable = true)\n",
      " |-- MASTER_TITLE: string (nullable = true)\n",
      " |-- RELEASE_YEAR: string (nullable = true)\n",
      " |-- EPISODE_TITLE: string (nullable = true)\n",
      " |-- EPISODE_NUMBER: string (nullable = true)\n",
      " |-- STEREO_ENABLED_YN: string (nullable = true)\n",
      " |-- STAR_RATING: string (nullable = true)\n",
      " |-- SERIES_YN: string (nullable = true)\n",
      " |-- RATING_ID_TV_US: string (nullable = true)\n",
      " |-- RATING_ID_MOVIE_US: string (nullable = true)\n",
      " |-- SERIES_MASTER_YN: string (nullable = true)\n",
      " |-- PARENT_PROGRAM_ID: string (nullable = true)\n",
      " |-- RUNTIME: string (nullable = true)\n",
      " |-- HDTV_YN: string (nullable = true)\n",
      " |-- BRACKET_TEXT: string (nullable = true)\n",
      " |-- PART_NUMBER: string (nullable = true)\n",
      " |-- PART_TOTAL: string (nullable = true)\n",
      " |-- ORIGINAL_ADT: string (nullable = true)\n",
      " |-- SUBTITLE: string (nullable = true)\n",
      " |-- EVENT_DATE: string (nullable = true)\n",
      " |-- TAG: string (nullable = true)\n",
      " |-- Cosmo_program_id: string (nullable = true)\n",
      " |-- link_region_id: string (nullable = true)\n",
      " |-- status_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "<console>",
     "evalue": "32: error: overloaded method value filter with alternatives:",
     "output_type": "error",
     "traceback": [
      "<console>:32: error: overloaded method value filter with alternatives:",
      "  (func: org.apache.spark.api.java.function.FilterFunction[org.apache.spark.sql.Row])org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] <and>",
      "  (func: org.apache.spark.sql.Row => Boolean)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] <and>",
      "  (conditionExpr: String)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] <and>",
      "  (condition: org.apache.spark.sql.Column)org.apache.spark.sql.Dataset[org.apache.spark.sql.Row]",
      " cannot be applied to (Boolean)",
      "       val df3 = df2.filter(\"EVENT_DATE\">\"2017-12-31\")",
      "                     ^",
      ""
     ]
    }
   ],
   "source": [
    "val df3 = df2.filter(\"EVENT_DATE\">\"2017-12-31\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
