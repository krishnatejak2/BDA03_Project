{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: org.apache.spark.sql.SparkSession = org.apache.spark.sql.SparkSession@50bdfae5\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_episode_df: org.apache.spark.sql.DataFrame = [PROGRAM_ID: string, PARENT_PROGRAM_ID: string ... 23 more fields]\n",
       "tivo_prog_df: org.apache.spark.sql.DataFrame = [MASTER_TITLE: string, EVENT_DATE: string ... 18 more fields]\n",
       "tivo_imdb_wiki_df: org.apache.spark.sql.DataFrame = [MASTER_TITLE: string, EVENT_DATE: string ... 25 more fields]\n"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val user_episode_df = spark.read.parquet(\"/Users/mthota/Dropbox/Data/final_datasets/users_program_data/\")\n",
    "val tivo_prog_df = spark.read.option(\"header\",\"true\").csv(\"/Users/mthota/Dropbox/Data/final_datasets/feature_enginnering/program_features/data_cleaned/csv/GenreImputed/ProgramMetadata.csv\")\n",
    "val tivo_imdb_wiki_df =spark.read.parquet(\"/Users/mthota/Dropbox/Data/final_datasets/feature_enginnering/program_features/program_features_tivo_imdb_wiki/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PROGRAM_ID: string (nullable = true)\n",
      " |-- PARENT_PROGRAM_ID: string (nullable = true)\n",
      " |-- PREV_PROGRAM_ID: string (nullable = true)\n",
      " |-- MASTER_TITLE: string (nullable = true)\n",
      " |-- EVENT_DATE: string (nullable = true)\n",
      " |-- CATEGORY_ID: string (nullable = true)\n",
      " |-- SUBCATEGORY_ID: string (nullable = true)\n",
      " |-- RUNTIME: string (nullable = true)\n",
      " |-- SK_DEVICE_ID: integer (nullable = true)\n",
      " |-- _c9: long (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- week_text: string (nullable = true)\n",
      " |-- week_encoded: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- vwp_days: string (nullable = true)\n",
      " |-- weekend: integer (nullable = true)\n",
      " |-- daypart: string (nullable = true)\n",
      " |-- weekOfTheYear: string (nullable = true)\n",
      " |-- EVENT_END_DATE: string (nullable = true)\n",
      " |-- airStartDate: string (nullable = true)\n",
      " |-- airStartTime: string (nullable = true)\n",
      " |-- airEndDate: string (nullable = true)\n",
      " |-- airEndTime: string (nullable = true)\n",
      " |-- AirYear: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- MASTER_TITLE: string (nullable = true)\n",
      " |-- EVENT_DATE: string (nullable = true)\n",
      " |-- CATEGORY_ID: string (nullable = true)\n",
      " |-- SUBCATEGORY_ID: string (nullable = true)\n",
      " |-- RUNTIME: string (nullable = true)\n",
      " |-- EPISODE_COUNT: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- week_text: string (nullable = true)\n",
      " |-- week_encoded: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- vwp_days: string (nullable = true)\n",
      " |-- weekend: string (nullable = true)\n",
      " |-- daypart: string (nullable = true)\n",
      " |-- weekOfTheYear: string (nullable = true)\n",
      " |-- EVENT_END_DATE: string (nullable = true)\n",
      " |-- airStartDate: string (nullable = true)\n",
      " |-- airStartTime: string (nullable = true)\n",
      " |-- airEndDate: string (nullable = true)\n",
      " |-- airEndTime: string (nullable = true)\n",
      " |-- AirYear: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- MASTER_TITLE: string (nullable = true)\n",
      " |-- EVENT_DATE: string (nullable = true)\n",
      " |-- CATEGORY_ID: string (nullable = true)\n",
      " |-- SUBCATEGORY_ID: string (nullable = true)\n",
      " |-- RUNTIME: string (nullable = true)\n",
      " |-- EPISODE_COUNT: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- week_text: string (nullable = true)\n",
      " |-- week_encoded: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- vwp_days: string (nullable = true)\n",
      " |-- weekend: string (nullable = true)\n",
      " |-- daypart: string (nullable = true)\n",
      " |-- weekOfTheYear: string (nullable = true)\n",
      " |-- EVENT_END_DATE: string (nullable = true)\n",
      " |-- airStartDate: string (nullable = true)\n",
      " |-- airStartTime: string (nullable = true)\n",
      " |-- airEndDate: string (nullable = true)\n",
      " |-- airEndTime: string (nullable = true)\n",
      " |-- AirYear: string (nullable = true)\n",
      " |-- imdb_program_id: string (nullable = true)\n",
      " |-- imdb_genres: string (nullable = true)\n",
      " |-- imdb_titleType: string (nullable = true)\n",
      " |-- imdb_averageRating: string (nullable = true)\n",
      " |-- imdb_numVotes: string (nullable = true)\n",
      " |-- imdb_cast_details: string (nullable = true)\n",
      " |-- wiki_summaries: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_episode_df.printSchema()\n",
    "tivo_prog_df.printSchema()\n",
    "tivo_imdb_wiki_df.printSchema()\n",
    "user_episode_df.createOrReplaceTempView(\"user_episode_df\")\n",
    "tivo_prog_df.createOrReplaceTempView(\"tivo_prog_df\")\n",
    "tivo_imdb_wiki_df.createOrReplaceTempView(\"tivo_imdb_wiki_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_episode_watch_df: org.apache.spark.sql.DataFrame = [PROGRAM_ID: string, PARENT_PROGRAM_ID: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val user_episode_watch_df  = spark.sql(\"SELECT PROGRAM_ID,PARENT_PROGRAM_ID,MASTER_TITLE,SK_DEVICE_ID as USER,CASE WHEN _c9 > RUNTIME THEN RUNTIME ELSE _c9 END as EPISODE_WATCH_DURATION,RUNTIME AS EPISODE_DURATION,(CASE WHEN _c9 > RUNTIME THEN RUNTIME ELSE _c9 END)/RUNTIME AS WATCH_RATIO FROM user_episode_df\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+-------------------------------+-------+----------------------+----------------+------------------+\n",
      "|PROGRAM_ID|PARENT_PROGRAM_ID|MASTER_TITLE                   |USER   |EPISODE_WATCH_DURATION|EPISODE_DURATION|WATCH_RATIO       |\n",
      "+----------+-----------------+-------------------------------+-------+----------------------+----------------+------------------+\n",
      "|14745095  |11533645         |The Good Doctor                |5118788|2505                  |3600            |0.6958333333333333|\n",
      "|14653884  |null             |One Winter Weekend             |5161679|7200                  |7200            |1.0               |\n",
      "|14962564  |6718065          |The Big Bang Theory            |5946021|1800                  |1800            |1.0               |\n",
      "|14802512  |7116387          |Keeping Up With the Kardashians|5139594|3600                  |3600            |1.0               |\n",
      "|14719450  |7060037          |Mom                            |5445265|1740                  |1740            |1.0               |\n",
      "|8110771   |7060037          |Mom                            |5165481|248                   |1740            |0.1425287356321839|\n",
      "|10413271  |5001966          |North Woods Law                |5115862|3600                  |3600            |1.0               |\n",
      "|14696213  |7731003          |Bull                           |5151153|3600                  |3600            |1.0               |\n",
      "|14761445  |11573609         |The Carbonaro Effect           |5103968|1450                  |1800            |0.8055555555555556|\n",
      "|10012975  |2764465          |Storage Wars                   |6259992|1800                  |1800            |1.0               |\n",
      "+----------+-----------------+-------------------------------+-------+----------------------+----------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_episode_watch_df.show(10,false)\n",
    "user_episode_watch_df.createOrReplaceTempView(\"user_episode_watch_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_program_metrics: org.apache.spark.sql.DataFrame = [USER: int, MASTER_TITLE: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val user_program_metrics = spark.sql(\"SELECT USER,MASTER_TITLE,SUM(EPISODE_WATCH_DURATION)/SUM(EPISODE_DURATION) as PROGRAM_WATCH_RATIO, COUNT(DISTINCT PROGRAM_ID) as EPISODES_WATCHED FROM user_episode_watch_df GROUP BY USER,MASTER_TITLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-23 18:26:36 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:36 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:36 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:36 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:38 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:38 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:38 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:38 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:39 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:39 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:39 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:39 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:40 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:40 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:40 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:40 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:42 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:42 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:42 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:42 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:43 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:43 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:43 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:43 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:44 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:44 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:44 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:44 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:45 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:45 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:45 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:45 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:46 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:46 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:47 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "2019-06-23 18:26:47 WARN  RowBasedKeyValueBatch:173 - Calling spill() on RowBasedKeyValueBatch. Will not spill but return 0.\n",
      "+-------+--------------------------------+-------------------+----------------+\n",
      "|USER   |MASTER_TITLE                    |PROGRAM_WATCH_RATIO|EPISODES_WATCHED|\n",
      "+-------+--------------------------------+-------------------+----------------+\n",
      "|5051529|Easter Island Unsolved          |0.195              |1               |\n",
      "|5057628|Arthur                          |0.0685897435897436 |1               |\n",
      "|5058196|iQ: smartparent                 |1.0                |2               |\n",
      "|5058432|Premier League Mornings         |1.0                |1               |\n",
      "|5058903|Outdaughtered                   |0.6831944444444444 |2               |\n",
      "|5059169|The Real Housewives of Atlanta  |1.0                |3               |\n",
      "|5059348|The Carbonaro Effect            |0.6909259259259259 |3               |\n",
      "|5059810|Impractical Jokers: Inside Jokes|0.8647892720306514 |29              |\n",
      "|5061631|9-1-1                           |0.34444444444444444|1               |\n",
      "|5066380|Married With Secrets            |1.0                |1               |\n",
      "+-------+--------------------------------+-------------------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_program_metrics.createOrReplaceTempView(\"user_program_metrics\")\n",
    "//user_program_metrics.show(10,false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res15: Long = 1837\n"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT MASTER_TITLE FROM user_episode_df WHERE CATEGORY_ID IN (3,4,5,8)\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_program_prefernce: org.apache.spark.sql.DataFrame = [USER: int, PROGRAM_WATCH_RATIO: double ... 23 more fields]\n"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val user_program_prefernce = spark.sql(\"SELECT USER,PROGRAM_WATCH_RATIO,EPISODES_WATCHED,EPISODES_WATCHED/EPISODE_COUNT AS USER_WATCH_FREQUENCY ,PROGRAM_WATCH_RATIO *(EPISODES_WATCHED/EPISODE_COUNT) AS USER_PROGRAM_PREFERANCE_METRIC,t.* from user_program_metrics u join tivo_prog_df t ON t.MASTER_TITLE = u.MASTER_TITLE ORDER BY USER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- USER: integer (nullable = true)\n",
      " |-- PROGRAM_WATCH_RATIO: double (nullable = true)\n",
      " |-- EPISODES_WATCHED: long (nullable = false)\n",
      " |-- USER_WATCH_FREQUENCY: double (nullable = true)\n",
      " |-- USER_PROGRAM_PREFERANCE_METRIC: double (nullable = true)\n",
      " |-- MASTER_TITLE: string (nullable = true)\n",
      " |-- EVENT_DATE: string (nullable = true)\n",
      " |-- CATEGORY_ID: string (nullable = true)\n",
      " |-- SUBCATEGORY_ID: string (nullable = true)\n",
      " |-- RUNTIME: string (nullable = true)\n",
      " |-- EPISODE_COUNT: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- week_text: string (nullable = true)\n",
      " |-- week_encoded: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- vwp_days: string (nullable = true)\n",
      " |-- weekend: string (nullable = true)\n",
      " |-- daypart: string (nullable = true)\n",
      " |-- weekOfTheYear: string (nullable = true)\n",
      " |-- EVENT_END_DATE: string (nullable = true)\n",
      " |-- airStartDate: string (nullable = true)\n",
      " |-- airStartTime: string (nullable = true)\n",
      " |-- airEndDate: string (nullable = true)\n",
      " |-- airEndTime: string (nullable = true)\n",
      " |-- AirYear: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_program_prefernce.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": " path file:/Users/mthota/Dropbox/Data/final_datasets/feature_enginnering/user_program_features/stage already exists.;",
     "output_type": "error",
     "traceback": [
      "org.apache.spark.sql.AnalysisException: path file:/Users/mthota/Dropbox/Data/final_datasets/feature_enginnering/user_program_features/stage already exists.;",
      "  at org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:109)",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)",
      "  at org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)",
      "  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)",
      "  at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)",
      "  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)",
      "  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:80)",
      "  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:80)",
      "  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)",
      "  at org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:654)",
      "  at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:77)",
      "  at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:654)",
      "  at org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:273)",
      "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:267)",
      "  at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:225)",
      "  at org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:547)",
      "  ... 36 elided",
      ""
     ]
    }
   ],
   "source": [
    "user_program_prefernce.createOrReplaceTempView(\"user_program_prefernce\")\n",
    "user_program_prefernce.write.parquet(\"/Users/mthota/Dropbox/Data/final_datasets/feature_enginnering/user_program_features/stage/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_preference: org.apache.spark.sql.DataFrame = [USER: int, PROGRAM_WATCH_RATIO: double ... 23 more fields]\n"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val user_preference = spark.read.parquet(\"/Users/mthota/Dropbox/Data/final_datasets/feature_enginnering/user_program_features/stage/\")\n",
    "user_program_prefernce.createOrReplaceTempView(\"user_program_prefernce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_program_prefernce_matrix: org.apache.spark.sql.DataFrame = [USER: int, PROGRAM_WATCH_RATIO: double ... 30 more fields]\n"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val user_program_prefernce_matrix = spark.sql(\"SELECT u.*,imdb_program_id,imdb_genres,imdb_titleType,imdb_averageRating,imdb_numVotes,imdb_cast_details,wiki_summaries from user_program_prefernce u left join tivo_imdb_wiki_df t on u.MASTER_TITLE=t.MASTER_TITLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- USER: integer (nullable = true)\n",
      " |-- PROGRAM_WATCH_RATIO: double (nullable = true)\n",
      " |-- EPISODES_WATCHED: long (nullable = false)\n",
      " |-- USER_WATCH_FREQUENCY: double (nullable = true)\n",
      " |-- USER_PROGRAM_PREFERANCE_METRIC: double (nullable = true)\n",
      " |-- MASTER_TITLE: string (nullable = true)\n",
      " |-- EVENT_DATE: string (nullable = true)\n",
      " |-- CATEGORY_ID: string (nullable = true)\n",
      " |-- SUBCATEGORY_ID: string (nullable = true)\n",
      " |-- RUNTIME: string (nullable = true)\n",
      " |-- EPISODE_COUNT: string (nullable = true)\n",
      " |-- day: string (nullable = true)\n",
      " |-- week_text: string (nullable = true)\n",
      " |-- week_encoded: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- vwp_days: string (nullable = true)\n",
      " |-- weekend: string (nullable = true)\n",
      " |-- daypart: string (nullable = true)\n",
      " |-- weekOfTheYear: string (nullable = true)\n",
      " |-- EVENT_END_DATE: string (nullable = true)\n",
      " |-- airStartDate: string (nullable = true)\n",
      " |-- airStartTime: string (nullable = true)\n",
      " |-- airEndDate: string (nullable = true)\n",
      " |-- airEndTime: string (nullable = true)\n",
      " |-- AirYear: string (nullable = true)\n",
      " |-- imdb_program_id: string (nullable = true)\n",
      " |-- imdb_genres: string (nullable = true)\n",
      " |-- imdb_titleType: string (nullable = true)\n",
      " |-- imdb_averageRating: string (nullable = true)\n",
      " |-- imdb_numVotes: string (nullable = true)\n",
      " |-- imdb_cast_details: string (nullable = true)\n",
      " |-- wiki_summaries: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_program_prefernce_matrix.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "    user_preference.repartition(1).write.parquet(\"/Users/mthota/Dropbox/Data/final_datasets/feature_enginnering/user_program_features/stage2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
