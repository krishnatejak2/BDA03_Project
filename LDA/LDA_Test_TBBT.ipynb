{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References :   \n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24  \n",
    "https://github.com/susanli2016/NLP-with-Python/blob/master/LDA_news_headlines.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two nerdy physicists share an apartment and an...</td>\n",
       "      <td>TBBT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Leonard and Sheldon meet their beautiful new n...</td>\n",
       "      <td>TBBT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The guys camp out in a line hoping to see an a...</td>\n",
       "      <td>TBBT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Howard and Raj try to discover where Sheldon d...</td>\n",
       "      <td>TBBT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After the guys, except for Sheldon, go camping...</td>\n",
       "      <td>TBBT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  name\n",
       "0  Two nerdy physicists share an apartment and an...  TBBT\n",
       "1  Leonard and Sheldon meet their beautiful new n...  TBBT\n",
       "2  The guys camp out in a line hoping to see an a...  TBBT\n",
       "3  Howard and Raj try to discover where Sheldon d...  TBBT\n",
       "4  After the guys, except for Sheldon, go camping...  TBBT"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_1 = pd.read_excel('./TBBT_Tivo.xlsx', error_bad_lines=False);\n",
    "data_1['name'] = 'TBBT'\n",
    "data_2 = pd.read_excel('./FIUP_Tivo.xlsx', error_bad_lines=False);\n",
    "data_2['name'] = 'FIUP'\n",
    "data_3 = pd.read_excel('./Ellen_Tivo.xlsx', error_bad_lines=False);\n",
    "data_3['name'] = 'ELLEN'\n",
    "data = data_1.append(data_2,ignore_index = False) \n",
    "data = data.append(data_3,ignore_index = False) \n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data[['description','name']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n",
      "                                         description  name  index\n",
      "0  Two nerdy physicists share an apartment and an...  TBBT      0\n",
      "1  Leonard and Sheldon meet their beautiful new n...  TBBT      1\n",
      "2  The guys camp out in a line hoping to see an a...  TBBT      2\n",
      "3  Howard and Raj try to discover where Sheldon d...  TBBT      3\n",
      "4  After the guys, except for Sheldon, go camping...  TBBT      4\n"
     ]
    }
   ],
   "source": [
    "print(len(documents))\n",
    "print(documents[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two nerdy physicists share an apartment and an...</td>\n",
       "      <td>TBBT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A house with three to four bedrooms and a spac...</td>\n",
       "      <td>FIUP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellen's flair for fun hits primetime with supe...</td>\n",
       "      <td>ELLEN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description   name  index\n",
       "0  Two nerdy physicists share an apartment and an...   TBBT      0\n",
       "0  A house with three to four bedrooms and a spac...   FIUP      0\n",
       "0  Ellen's flair for fun hits primetime with supe...  ELLEN      0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[documents.index==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/krishna/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk import stem\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\" \".join(SnowballStemmer.languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Two', 'nerdy', 'physicists', 'share', 'an', 'apartment', 'and', 'an', 'unlikely', 'friendship', 'with', 'their', 'beautiful', 'neighbor', 'with', 'whom', 'one', 'of', 'them', 'is', 'infatuated.', 'Like', 'the', 'universe', 'after', 'the', 'big', 'bang,', 'the', \"show's\", 'popularity', 'expanded,', 'thanks', 'to', 'breakout', 'star', 'Jim', 'Parsons,', 'along', 'with', 'the', 'chemistry', 'among', 'the', 'friends', 'and', 'the', 'developing', 'romance', 'between', 'Leonard', 'and', 'Penny.', 'The', 'addition', 'of', 'Melissa', 'Rauch', 'and', 'Mayim', 'Bialik', 'in', 'later', 'seasons', 'also', 'enhanced', 'the', 'stories', 'and', 'relationships', 'of', 'the', 'leads.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['nerdi', 'physicist', 'share', 'apart', 'unlik', 'friendship', 'beauti', 'neighbor', 'infatu', 'like', 'univers', 'bang', 'popular', 'expand', 'thank', 'breakout', 'star', 'parson', 'chemistri', 'friend', 'develop', 'romanc', 'leonard', 'penni', 'addit', 'melissa', 'rauch', 'mayim', 'bialik', 'later', 'season', 'enhanc', 'stori', 'relationship', 'lead']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 0].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [nerdi, physicist, share, apart, unlik, friend...\n",
       "1    [leonard, sheldon, meet, beauti, neighbor, inv...\n",
       "2    [guy, camp, line, hop, anticip, movi, penni, b...\n",
       "3    [howard, discov, sheldon, disappear, afternoon...\n",
       "4    [guy, sheldon, camp, penni, injur, leav, sheld...\n",
       "5    [priya, use, legal, expertis, apart, sheldon, ...\n",
       "6    [attract, penni, boyfriend, howard, argu, bett...\n",
       "7    [howard, baffl, sheldon, accept, apolog, agent...\n",
       "8    [second, season, open, penni, surpris, turn, s...\n",
       "9    [guy, road, trip, comic, book, convent, bakers...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs = documents['description'].map(preprocess)\n",
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 addit\n",
      "1 apart\n",
      "2 bang\n",
      "3 beauti\n",
      "4 bialik\n",
      "5 breakout\n",
      "6 chemistri\n",
      "7 develop\n",
      "8 enhanc\n",
      "9 expand\n",
      "10 friend\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3812"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break\n",
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'infatu'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=2, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 1),\n",
       " (9, 2),\n",
       " (11, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 1),\n",
       " (28, 1),\n",
       " (29, 1),\n",
       " (30, 1),\n",
       " (31, 1),\n",
       " (32, 1),\n",
       " (33, 1),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 1),\n",
       " (37, 1),\n",
       " (38, 1),\n",
       " (39, 1)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 0 (\"addit\") appears 1 time.\n",
      "Word 1 (\"apart\") appears 1 time.\n",
      "Word 2 (\"bang\") appears 1 time.\n",
      "Word 3 (\"beauti\") appears 1 time.\n",
      "Word 4 (\"develop\") appears 1 time.\n",
      "Word 5 (\"friend\") appears 1 time.\n",
      "Word 6 (\"friendship\") appears 1 time.\n",
      "Word 7 (\"later\") appears 1 time.\n",
      "Word 8 (\"lead\") appears 1 time.\n",
      "Word 9 (\"leonard\") appears 1 time.\n",
      "Word 10 (\"like\") appears 1 time.\n",
      "Word 11 (\"neighbor\") appears 1 time.\n",
      "Word 12 (\"parson\") appears 1 time.\n",
      "Word 13 (\"penni\") appears 1 time.\n",
      "Word 14 (\"physicist\") appears 1 time.\n",
      "Word 15 (\"popular\") appears 1 time.\n",
      "Word 16 (\"relationship\") appears 1 time.\n",
      "Word 17 (\"romanc\") appears 1 time.\n",
      "Word 18 (\"season\") appears 1 time.\n",
      "Word 19 (\"share\") appears 1 time.\n",
      "Word 20 (\"star\") appears 1 time.\n",
      "Word 21 (\"stori\") appears 1 time.\n",
      "Word 22 (\"univers\") appears 1 time.\n",
      "Word 23 (\"unlik\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[0]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                                     dictionary[bow_doc_4310[i][0]], \n",
    "                                                     bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.2644718102762352),\n",
      " (1, 0.16707490095071303),\n",
      " (2, 0.24601861988302015),\n",
      " (3, 0.2074571051562886),\n",
      " (4, 0.23292587293757588),\n",
      " (5, 0.1281325374127274),\n",
      " (6, 0.22277034942870522),\n",
      " (7, 0.19601949215114584),\n",
      " (8, 0.1829267452057016),\n",
      " (9, 0.06532600014254476),\n",
      " (10, 0.19601949215114584),\n",
      " (11, 0.24601861988302015),\n",
      " (12, 0.2644718102762352),\n",
      " (13, 0.06828230983117356),\n",
      " (14, 0.2144726825443609),\n",
      " (15, 0.2644718102762352),\n",
      " (16, 0.15331774560157696),\n",
      " (17, 0.2144726825443609),\n",
      " (18, 0.13973298124401312),\n",
      " (19, 0.22277034942870522),\n",
      " (20, 0.2074571051562886),\n",
      " (21, 0.20137993559891662),\n",
      " (22, 0.17277122169683093),\n",
      " (23, 0.24601861988302015)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.042*\"penni\" + 0.041*\"sheldon\" + 0.035*\"leonard\" + 0.018*\"wolowitz\" + 0.018*\"bernadett\" + 0.012*\"howard\" + 0.010*\"friend\" + 0.009*\"guy\" + 0.009*\"para\" + 0.008*\"help\"\n",
      "Topic: 1 \n",
      "Words: 0.032*\"sheldon\" + 0.022*\"howard\" + 0.019*\"bernadett\" + 0.019*\"leonard\" + 0.011*\"friend\" + 0.011*\"seri\" + 0.011*\"final\" + 0.010*\"penni\" + 0.010*\"get\" + 0.010*\"make\"\n",
      "Topic: 2 \n",
      "Words: 0.035*\"sheldon\" + 0.023*\"leonard\" + 0.021*\"date\" + 0.012*\"wolowitz\" + 0.011*\"howard\" + 0.010*\"apart\" + 0.010*\"take\" + 0.008*\"penni\" + 0.008*\"ask\" + 0.007*\"friend\"\n",
      "Topic: 3 \n",
      "Words: 0.040*\"leonard\" + 0.035*\"penni\" + 0.034*\"sheldon\" + 0.018*\"howard\" + 0.013*\"women\" + 0.012*\"bernadett\" + 0.011*\"talk\" + 0.009*\"siƒô\" + 0.009*\"comic\" + 0.008*\"decid\"\n",
      "Topic: 4 \n",
      "Words: 0.016*\"chip\" + 0.014*\"sheldon\" + 0.011*\"discuss\" + 0.010*\"joanna\" + 0.009*\"cameo\" + 0.009*\"famili\" + 0.009*\"texa\" + 0.009*\"coupl\" + 0.008*\"home\" + 0.007*\"hous\"\n",
      "Topic: 5 \n",
      "Words: 0.042*\"home\" + 0.037*\"texa\" + 0.028*\"famili\" + 0.027*\"waco\" + 0.023*\"chip\" + 0.020*\"coupl\" + 0.017*\"hous\" + 0.017*\"budget\" + 0.013*\"search\" + 0.010*\"live\"\n",
      "Topic: 6 \n",
      "Words: 0.018*\"sheldon\" + 0.014*\"chip\" + 0.012*\"leonard\" + 0.011*\"home\" + 0.010*\"penni\" + 0.009*\"coupl\" + 0.009*\"pour\" + 0.009*\"compet\" + 0.008*\"contest\" + 0.008*\"joanna\"\n",
      "Topic: 7 \n",
      "Words: 0.023*\"chip\" + 0.016*\"hous\" + 0.014*\"home\" + 0.013*\"sheldon\" + 0.011*\"waco\" + 0.011*\"leonard\" + 0.011*\"joanna\" + 0.011*\"penni\" + 0.011*\"help\" + 0.009*\"work\"\n",
      "Topic: 8 \n",
      "Words: 0.027*\"advanc\" + 0.026*\"game\" + 0.021*\"chanc\" + 0.020*\"round\" + 0.020*\"cash\" + 0.019*\"know\" + 0.019*\"winner\" + 0.018*\"contest\" + 0.017*\"hand\" + 0.017*\"win\"\n",
      "Topic: 9 \n",
      "Words: 0.055*\"sheldon\" + 0.040*\"leonard\" + 0.037*\"penni\" + 0.014*\"howard\" + 0.011*\"date\" + 0.011*\"game\" + 0.010*\"bernadett\" + 0.010*\"parti\" + 0.009*\"season\" + 0.008*\"get\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.007*\"wolowitz\" + 0.007*\"sheldon\" + 0.006*\"wheaton\" + 0.006*\"look\" + 0.006*\"leonard\" + 0.005*\"reveal\" + 0.005*\"husband\" + 0.005*\"weekend\" + 0.005*\"spend\" + 0.005*\"secret\"\n",
      "Topic: 1 Word: 0.009*\"sheldon\" + 0.009*\"leonard\" + 0.007*\"penni\" + 0.007*\"visit\" + 0.006*\"howard\" + 0.006*\"think\" + 0.005*\"bernadett\" + 0.005*\"live\" + 0.005*\"friend\" + 0.005*\"onlin\"\n",
      "Topic: 2 Word: 0.013*\"advanc\" + 0.011*\"round\" + 0.010*\"game\" + 0.009*\"prize\" + 0.009*\"winner\" + 0.009*\"contest\" + 0.008*\"know\" + 0.008*\"chanc\" + 0.008*\"hand\" + 0.008*\"cash\"\n",
      "Topic: 3 Word: 0.005*\"chip\" + 0.005*\"hecho\" + 0.005*\"sheldon\" + 0.005*\"gang\" + 0.004*\"question\" + 0.004*\"breakfast\" + 0.004*\"tournament\" + 0.004*\"race\" + 0.004*\"programa\" + 0.004*\"coverag\"\n",
      "Topic: 4 Word: 0.006*\"penni\" + 0.006*\"naar\" + 0.006*\"continu\" + 0.005*\"high\" + 0.005*\"leav\" + 0.005*\"sheldon\" + 0.005*\"desd\" + 0.005*\"forc\" + 0.005*\"take\" + 0.005*\"home\"\n",
      "Topic: 5 Word: 0.007*\"leonard\" + 0.006*\"bernadett\" + 0.006*\"state\" + 0.006*\"penni\" + 0.005*\"home\" + 0.005*\"howard\" + 0.005*\"attempt\" + 0.005*\"sheldon\" + 0.005*\"date\" + 0.005*\"replay\"\n",
      "Topic: 6 Word: 0.008*\"sheldon\" + 0.007*\"leonard\" + 0.006*\"penni\" + 0.006*\"seri\" + 0.006*\"famili\" + 0.005*\"babi\" + 0.005*\"time\" + 0.005*\"texa\" + 0.005*\"band\" + 0.005*\"chip\"\n",
      "Topic: 7 Word: 0.007*\"waco\" + 0.007*\"texa\" + 0.007*\"build\" + 0.007*\"chip\" + 0.006*\"insid\" + 0.005*\"hous\" + 0.005*\"move\" + 0.005*\"sheldon\" + 0.005*\"look\" + 0.005*\"home\"\n",
      "Topic: 8 Word: 0.008*\"sheldon\" + 0.008*\"penni\" + 0.008*\"seek\" + 0.006*\"leonard\" + 0.006*\"scienc\" + 0.006*\"howard\" + 0.006*\"surpris\" + 0.006*\"fight\" + 0.006*\"famili\" + 0.006*\"date\"\n",
      "Topic: 9 Word: 0.008*\"leonard\" + 0.007*\"sheldon\" + 0.006*\"date\" + 0.006*\"budget\" + 0.006*\"penni\" + 0.005*\"apart\" + 0.005*\"michael\" + 0.005*\"space\" + 0.005*\"larg\" + 0.005*\"search\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [nerdi, physicist, share, apart, unlik, friend...\n",
       "0    [hous, bedroom, space, turn, playroom, home, o...\n",
       "0    [ellen, flair, hit, primetim, supers, version,...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.44466906785964966\t \n",
      "Topic: 0.055*\"sheldon\" + 0.040*\"leonard\" + 0.037*\"penni\" + 0.014*\"howard\" + 0.011*\"date\" + 0.011*\"game\" + 0.010*\"bernadett\" + 0.010*\"parti\" + 0.009*\"season\" + 0.008*\"get\"\n",
      "\n",
      "Score: 0.3416323959827423\t \n",
      "Topic: 0.035*\"sheldon\" + 0.023*\"leonard\" + 0.021*\"date\" + 0.012*\"wolowitz\" + 0.011*\"howard\" + 0.010*\"apart\" + 0.010*\"take\" + 0.008*\"penni\" + 0.008*\"ask\" + 0.007*\"friend\"\n",
      "\n",
      "Score: 0.18568678200244904\t \n",
      "Topic: 0.018*\"sheldon\" + 0.014*\"chip\" + 0.012*\"leonard\" + 0.011*\"home\" + 0.010*\"penni\" + 0.009*\"coupl\" + 0.009*\"pour\" + 0.009*\"compet\" + 0.008*\"contest\" + 0.008*\"joanna\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[0]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9639757871627808\t \n",
      "Topic: 0.007*\"leonard\" + 0.006*\"bernadett\" + 0.006*\"state\" + 0.006*\"penni\" + 0.005*\"home\" + 0.005*\"howard\" + 0.005*\"attempt\" + 0.005*\"sheldon\" + 0.005*\"date\" + 0.005*\"replay\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[0]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6999204754829407\t Topic: 0.023*\"chip\" + 0.016*\"hous\" + 0.014*\"home\" + 0.013*\"sheldon\" + 0.011*\"waco\"\n",
      "Score: 0.0333574116230011\t Topic: 0.035*\"sheldon\" + 0.023*\"leonard\" + 0.021*\"date\" + 0.012*\"wolowitz\" + 0.011*\"howard\"\n",
      "Score: 0.033345017582178116\t Topic: 0.018*\"sheldon\" + 0.014*\"chip\" + 0.012*\"leonard\" + 0.011*\"home\" + 0.010*\"penni\"\n",
      "Score: 0.03334338217973709\t Topic: 0.042*\"penni\" + 0.041*\"sheldon\" + 0.035*\"leonard\" + 0.018*\"wolowitz\" + 0.018*\"bernadett\"\n",
      "Score: 0.033343032002449036\t Topic: 0.042*\"home\" + 0.037*\"texa\" + 0.028*\"famili\" + 0.027*\"waco\" + 0.023*\"chip\"\n",
      "Score: 0.033342961221933365\t Topic: 0.032*\"sheldon\" + 0.022*\"howard\" + 0.019*\"bernadett\" + 0.019*\"leonard\" + 0.011*\"friend\"\n",
      "Score: 0.033338844776153564\t Topic: 0.016*\"chip\" + 0.014*\"sheldon\" + 0.011*\"discuss\" + 0.010*\"joanna\" + 0.009*\"cameo\"\n",
      "Score: 0.03333630785346031\t Topic: 0.040*\"leonard\" + 0.035*\"penni\" + 0.034*\"sheldon\" + 0.018*\"howard\" + 0.013*\"women\"\n",
      "Score: 0.03333630412817001\t Topic: 0.027*\"advanc\" + 0.026*\"game\" + 0.021*\"chanc\" + 0.020*\"round\" + 0.020*\"cash\"\n",
      "Score: 0.033336248248815536\t Topic: 0.055*\"sheldon\" + 0.040*\"leonard\" + 0.037*\"penni\" + 0.014*\"howard\" + 0.011*\"date\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'This house is up for sale or for escrow'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00360392, 0.25499205, 0.0036211 , 0.64236448, 0.09541846],\n",
       "       [0.15297572, 0.00362644, 0.44412786, 0.39568399, 0.003586  ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "# This produces a feature matrix of token counts, similar to what\n",
    "# CountVectorizer would produce on text.\n",
    "X, _ = make_multilabel_classification(random_state=0)\n",
    "lda = LatentDirichletAllocation(n_components=5,random_state=0)\n",
    "lda.fit(X) \n",
    "# LatentDirichletAllocation(...)\n",
    "# get topics for some given samples:\n",
    "lda.transform(X[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 1., 4., 0., 3., 0., 7., 2., 1., 0., 5., 3., 4., 6., 0., 2., 5.,\n",
       "       4., 1., 3.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 1],\n",
       "       [0, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0],\n",
       "       [1, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 1],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [1, 1, 0, 1, 0],\n",
       "       [1, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 1],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [1, 1, 1, 0, 1],\n",
       "       [0, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [0, 1, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 1],\n",
       "       [1, 0, 1, 1, 1],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 1, 0],\n",
       "       [0, 1, 1, 0, 1],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [1, 0, 1, 1, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 1],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [1, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 0],\n",
       "       [0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 1],\n",
       "       [0, 0, 1, 0, 0],\n",
       "       [0, 1, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 1]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
